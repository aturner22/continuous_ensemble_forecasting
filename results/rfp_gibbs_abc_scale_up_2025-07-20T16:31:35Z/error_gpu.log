Loading batches:   0%|          | 0/1024 [00:00<?, ?it/s]Loading batches: 100%|██████████| 1024/1024 [00:00<00:00, 2894182.81it/s]
Gibbs Sampling Steps:   0%|          | 0/3 [00:00<?, ?it/s]Gibbs Sampling Steps:   0%|          | 0/3 [03:52<?, ?it/s]
Traceback (most recent call last):
  File "/rds/general/user/at1824/home/msc_project/rfp_gibbs_main.py", line 96, in <module>
    results = run_gibbs_abc_rfp(
  File "/rds/general/user/at1824/home/msc_project/core/gibbs_abc_threaded_rfp.py", line 178, in run_gibbs_abc_rfp
    ensemble_tensor, target_tensor = generate_batched_ensemble_from_mmap(
  File "/rds/general/user/at1824/home/msc_project/core/gibbs_abc_threaded_rfp.py", line 94, in generate_batched_ensemble_from_mmap
    out = model(full_input_tensor[input_start:input_end], full_time_tensor[input_start:input_end]).detach()
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/diffusion_networks.py", line 417, in forward
    D_x = self.model(x, time_labels, class_labels=class_labels).to(torch.float32)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/diffusion_networks.py", line 375, in forward
    x = block(x, emb) if isinstance(block, UNetBlock) else block(x)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/diffusion_networks.py", line 182, in forward
    x = self.conv0(silu(self.norm0(x)))
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/diffusion_networks.py", line 102, in forward
    x = self.circ_pad(x, w_pad)
  File "/rds/general/user/at1824/home/msc_project/diffusion_networks.py", line 72, in circ_pad
    return pad_func(x) if pad else x
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/modules/padding.py", line 42, in forward
    return F.pad(input, self.padding, "circular")
  File "/rds/general/user/at1824/home/msc_project/venv/lib/python3.10/site-packages/torch/nn/functional.py", line 5209, in pad
    return torch._C._nn.pad(input, pad, mode, value)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.45 GiB. GPU 0 has a total capacity of 44.42 GiB of which 7.31 GiB is free. Including non-PyTorch memory, this process has 37.10 GiB memory in use. Of the allocated memory 35.91 GiB is allocated by PyTorch, and 710.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
